{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca05710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import dataloader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b12006ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=100\n",
    "batch_size_train=400\n",
    "batch_size_test=1000\n",
    "log_interval=1\n",
    "random_seed=6\n",
    "torch.manual_seed(random_seed)\n",
    "learning_rate = 0.01\n",
    "momentum=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1502c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data/',train=True,download=True,transform=torchvision.transforms.Compose([torchvision.transforms.RandomAffine(degrees = 0,translate=(0.1, 0.1)),\n",
    "                                   torchvision.transforms.RandomRotation((-10,10)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,),(0.3081,))#,torchvision.transforms.Resize([96,96])\n",
    "    ])),batch_size=batch_size_train,shuffle=True)\n",
    "test_loader=test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             #,torchvision.transforms.Resize([96,96])\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6bec48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea30e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "      plt.subplot(2,3,i+1)\n",
    "      plt.tight_layout()\n",
    "      plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "      plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "      plt.xticks([])\n",
    "      plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff1d783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Convolution layer 1 (（w - f + 2 * p）/ s ) + 1\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1 , out_channels = 32, kernel_size = 5, stride = 1, padding = 0 )\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.batch1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels =32 , out_channels = 64, kernel_size = 3, stride = 1, padding = 0 )\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batch2 = nn.BatchNorm2d(64)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv1_drop = nn.Dropout(0.25)\n",
    "\n",
    "        # Convolution layer 2\n",
    "        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0 )\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.batch3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0 )\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.batch4 = nn.BatchNorm2d(256)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2_drop = nn.Dropout(0.25)\n",
    "\n",
    "        # Fully-Connected layer 1\n",
    "        \n",
    "        self.fc1 = nn.Linear(2304,512)\n",
    "        self.fc1_relu = nn.ReLU()\n",
    "        self.dp1 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Fully-Connected layer 2\n",
    "        self.fc2 = nn.Linear(512,10)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # conv layer 1 的前向计算，3行代码\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.batch1(out)\n",
    "        #out = self.conv1_drop(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.batch2(out)\n",
    "        \n",
    "        out = self.maxpool1(out)\n",
    "        out = self.conv1_drop(out)\n",
    "\n",
    "        # conv layer 2 的前向计算，4行代码\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.batch3(out)\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.batch4(out)\n",
    "        \n",
    "        out = self.maxpool2(out)\n",
    "        out = self.conv2_drop(out)\n",
    "\n",
    "        #Flatten拉平操作\n",
    "        out = out.view(out.size(0),-1)\n",
    "\n",
    "        #FC layer的前向计算（2行代码）\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc1_relu(out)\n",
    "        out = self.dp1(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return F.log_softmax(out,dim = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f4998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8744c38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (batch1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (batch2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1_drop): Dropout(p=0.25, inplace=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu3): ReLU()\n",
       "  (batch3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu4): ReLU()\n",
       "  (batch4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_drop): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=2304, out_features=512, bias=True)\n",
       "  (fc1_relu): ReLU()\n",
       "  (dp1): Dropout(p=0.3, inplace=False)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "     \n",
    "device=torch.device('cuda:0'if torch.cuda.is_available()else 'cpu')\n",
    "\n",
    "network.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b9e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置优化器，用stochastic gradient descent，设置学习率，设置momentum\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "#optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "#optimizer = optim.RMSprop(network.parameters(),lr=learning_rate,alpha=0.99,momentum = momentum)\n",
    "#设置学习率梯度下降，如果连续三个epoch测试准确率没有上升，则降低学习率\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True, threshold=0.00005, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a85ec071",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0aee2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "      #network=\n",
    "      network.to(device)\n",
    "      network.train()\n",
    "      \n",
    "      for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data=data.to(device)\n",
    "            target=target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data)\n",
    "            #output.to(device)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % (log_interval) == 0:\n",
    "                  print('\\r Train Epoch: {} [{}/{} ({:.2f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()),end='')\n",
    "                  train_losses.append(loss.item())\n",
    "                  train_counter.append(\n",
    "                    (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "                  torch.save(network.state_dict(), './model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "144a5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  #network=network.to(device)\n",
    "  network.eval()\n",
    "  network.to(device)\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      \n",
    "      data=data.to(device)\n",
    "      target=target.to(device)\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e07b2665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 0 [59600/60000 (99.33%)]\tLoss: 0.339131"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sad/anaconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0963, Accuracy: 9760/10000 (97.60%)\n",
      "\n",
      " Train Epoch: 1 [59600/60000 (99.33%)]\tLoss: 0.173006\n",
      "Test set: Avg. loss: 0.0577, Accuracy: 9841/10000 (98.41%)\n",
      "\n",
      " Train Epoch: 2 [59600/60000 (99.33%)]\tLoss: 0.151643\n",
      "Test set: Avg. loss: 0.0456, Accuracy: 9878/10000 (98.78%)\n",
      "\n",
      " Train Epoch: 3 [59600/60000 (99.33%)]\tLoss: 0.153224\n",
      "Test set: Avg. loss: 0.0362, Accuracy: 9906/10000 (99.06%)\n",
      "\n",
      " Train Epoch: 4 [59600/60000 (99.33%)]\tLoss: 0.104037\n",
      "Test set: Avg. loss: 0.0343, Accuracy: 9889/10000 (98.89%)\n",
      "\n",
      " Train Epoch: 5 [59600/60000 (99.33%)]\tLoss: 0.109279\n",
      "Test set: Avg. loss: 0.0332, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      " Train Epoch: 6 [59600/60000 (99.33%)]\tLoss: 0.112317\n",
      "Test set: Avg. loss: 0.0278, Accuracy: 9916/10000 (99.16%)\n",
      "\n",
      " Train Epoch: 7 [59600/60000 (99.33%)]\tLoss: 0.048843\n",
      "Test set: Avg. loss: 0.0259, Accuracy: 9927/10000 (99.27%)\n",
      "\n",
      " Train Epoch: 8 [59600/60000 (99.33%)]\tLoss: 0.085935\n",
      "Test set: Avg. loss: 0.0274, Accuracy: 9923/10000 (99.23%)\n",
      "\n",
      " Train Epoch: 9 [59600/60000 (99.33%)]\tLoss: 0.087759\n",
      "Test set: Avg. loss: 0.0251, Accuracy: 9926/10000 (99.26%)\n",
      "\n",
      " Train Epoch: 10 [59600/60000 (99.33%)]\tLoss: 0.091556\n",
      "Test set: Avg. loss: 0.0225, Accuracy: 9931/10000 (99.31%)\n",
      "\n",
      " Train Epoch: 11 [59600/60000 (99.33%)]\tLoss: 0.036265\n",
      "Test set: Avg. loss: 0.0203, Accuracy: 9943/10000 (99.43%)\n",
      "\n",
      " Train Epoch: 12 [59600/60000 (99.33%)]\tLoss: 0.045312\n",
      "Test set: Avg. loss: 0.0201, Accuracy: 9939/10000 (99.39%)\n",
      "\n",
      " Train Epoch: 13 [59600/60000 (99.33%)]\tLoss: 0.038361\n",
      "Test set: Avg. loss: 0.0183, Accuracy: 9946/10000 (99.46%)\n",
      "\n",
      " Train Epoch: 14 [59600/60000 (99.33%)]\tLoss: 0.052199\n",
      "Test set: Avg. loss: 0.0172, Accuracy: 9952/10000 (99.52%)\n",
      "\n",
      " Train Epoch: 15 [59600/60000 (99.33%)]\tLoss: 0.098461\n",
      "Test set: Avg. loss: 0.0169, Accuracy: 9949/10000 (99.49%)\n",
      "\n",
      " Train Epoch: 16 [59600/60000 (99.33%)]\tLoss: 0.067528\n",
      "Test set: Avg. loss: 0.0166, Accuracy: 9948/10000 (99.48%)\n",
      "\n",
      " Train Epoch: 17 [59600/60000 (99.33%)]\tLoss: 0.083372\n",
      "Test set: Avg. loss: 0.0170, Accuracy: 9947/10000 (99.47%)\n",
      "\n",
      " Train Epoch: 18 [59600/60000 (99.33%)]\tLoss: 0.043241\n",
      "Test set: Avg. loss: 0.0159, Accuracy: 9953/10000 (99.53%)\n",
      "\n",
      " Train Epoch: 19 [59600/60000 (99.33%)]\tLoss: 0.041715\n",
      "Test set: Avg. loss: 0.0177, Accuracy: 9945/10000 (99.45%)\n",
      "\n",
      " Train Epoch: 20 [59600/60000 (99.33%)]\tLoss: 0.042524\n",
      "Test set: Avg. loss: 0.0164, Accuracy: 9953/10000 (99.53%)\n",
      "\n",
      " Train Epoch: 21 [59600/60000 (99.33%)]\tLoss: 0.066839\n",
      "Test set: Avg. loss: 0.0170, Accuracy: 9945/10000 (99.45%)\n",
      "\n",
      " Train Epoch: 22 [59600/60000 (99.33%)]\tLoss: 0.052748\n",
      "Test set: Avg. loss: 0.0163, Accuracy: 9948/10000 (99.48%)\n",
      "\n",
      " Train Epoch: 23 [59600/60000 (99.33%)]\tLoss: 0.044174\n",
      "Test set: Avg. loss: 0.0145, Accuracy: 9952/10000 (99.52%)\n",
      "\n",
      " Train Epoch: 24 [59600/60000 (99.33%)]\tLoss: 0.039607\n",
      "Test set: Avg. loss: 0.0153, Accuracy: 9954/10000 (99.54%)\n",
      "\n",
      " Train Epoch: 25 [59600/60000 (99.33%)]\tLoss: 0.036879\n",
      "Test set: Avg. loss: 0.0143, Accuracy: 9957/10000 (99.57%)\n",
      "\n",
      " Train Epoch: 26 [59600/60000 (99.33%)]\tLoss: 0.034710\n",
      "Test set: Avg. loss: 0.0149, Accuracy: 9950/10000 (99.50%)\n",
      "\n",
      " Train Epoch: 27 [59600/60000 (99.33%)]\tLoss: 0.056084\n",
      "Test set: Avg. loss: 0.0147, Accuracy: 9950/10000 (99.50%)\n",
      "\n",
      " Train Epoch: 28 [59600/60000 (99.33%)]\tLoss: 0.033423\n",
      "Test set: Avg. loss: 0.0141, Accuracy: 9952/10000 (99.52%)\n",
      "\n",
      " Train Epoch: 29 [59600/60000 (99.33%)]\tLoss: 0.053738\n",
      "Test set: Avg. loss: 0.0137, Accuracy: 9950/10000 (99.50%)\n",
      "\n",
      " Train Epoch: 30 [59600/60000 (99.33%)]\tLoss: 0.023350\n",
      "Test set: Avg. loss: 0.0145, Accuracy: 9956/10000 (99.56%)\n",
      "\n",
      " Train Epoch: 31 [59600/60000 (99.33%)]\tLoss: 0.058450\n",
      "Test set: Avg. loss: 0.0147, Accuracy: 9954/10000 (99.54%)\n",
      "\n",
      " Train Epoch: 32 [59600/60000 (99.33%)]\tLoss: 0.062877\n",
      "Test set: Avg. loss: 0.0133, Accuracy: 9959/10000 (99.59%)\n",
      "\n",
      " Train Epoch: 33 [59600/60000 (99.33%)]\tLoss: 0.063508\n",
      "Test set: Avg. loss: 0.0132, Accuracy: 9957/10000 (99.57%)\n",
      "\n",
      " Train Epoch: 34 [59600/60000 (99.33%)]\tLoss: 0.043504\n",
      "Test set: Avg. loss: 0.0133, Accuracy: 9955/10000 (99.55%)\n",
      "\n",
      " Train Epoch: 35 [59600/60000 (99.33%)]\tLoss: 0.028390\n",
      "Test set: Avg. loss: 0.0133, Accuracy: 9956/10000 (99.56%)\n",
      "\n",
      " Train Epoch: 36 [59600/60000 (99.33%)]\tLoss: 0.058962\n",
      "Test set: Avg. loss: 0.0134, Accuracy: 9957/10000 (99.57%)\n",
      "\n",
      " Train Epoch: 37 [59600/60000 (99.33%)]\tLoss: 0.037776\n",
      "Test set: Avg. loss: 0.0136, Accuracy: 9955/10000 (99.55%)\n",
      "\n",
      " Train Epoch: 38 [59600/60000 (99.33%)]\tLoss: 0.056754\n",
      "Test set: Avg. loss: 0.0131, Accuracy: 9958/10000 (99.58%)\n",
      "\n",
      " Train Epoch: 39 [59600/60000 (99.33%)]\tLoss: 0.012563\n",
      "Test set: Avg. loss: 0.0142, Accuracy: 9948/10000 (99.48%)\n",
      "\n",
      " Train Epoch: 40 [59600/60000 (99.33%)]\tLoss: 0.023057\n",
      "Test set: Avg. loss: 0.0134, Accuracy: 9954/10000 (99.54%)\n",
      "\n",
      " Train Epoch: 41 [59600/60000 (99.33%)]\tLoss: 0.049949\n",
      "Test set: Avg. loss: 0.0129, Accuracy: 9960/10000 (99.60%)\n",
      "\n",
      " Train Epoch: 42 [59600/60000 (99.33%)]\tLoss: 0.014724\n",
      "Test set: Avg. loss: 0.0122, Accuracy: 9957/10000 (99.57%)\n",
      "\n",
      " Train Epoch: 43 [59600/60000 (99.33%)]\tLoss: 0.039971\n",
      "Test set: Avg. loss: 0.0132, Accuracy: 9954/10000 (99.54%)\n",
      "\n",
      " Train Epoch: 44 [59600/60000 (99.33%)]\tLoss: 0.008759\n",
      "Test set: Avg. loss: 0.0130, Accuracy: 9958/10000 (99.58%)\n",
      "\n",
      " Train Epoch: 45 [59600/60000 (99.33%)]\tLoss: 0.028980\n",
      "Test set: Avg. loss: 0.0125, Accuracy: 9956/10000 (99.56%)\n",
      "\n",
      " Train Epoch: 46 [59600/60000 (99.33%)]\tLoss: 0.021411\n",
      "Test set: Avg. loss: 0.0126, Accuracy: 9955/10000 (99.55%)\n",
      "\n",
      " Train Epoch: 47 [59600/60000 (99.33%)]\tLoss: 0.024138\n",
      "Test set: Avg. loss: 0.0122, Accuracy: 9960/10000 (99.60%)\n",
      "\n",
      " Train Epoch: 48 [59600/60000 (99.33%)]\tLoss: 0.035800\n",
      "Test set: Avg. loss: 0.0120, Accuracy: 9955/10000 (99.55%)\n",
      "\n",
      " Train Epoch: 49 [59600/60000 (99.33%)]\tLoss: 0.032370\n",
      "Test set: Avg. loss: 0.0127, Accuracy: 9955/10000 (99.55%)\n",
      "\n",
      " Train Epoch: 50 [59600/60000 (99.33%)]\tLoss: 0.039830\n",
      "Test set: Avg. loss: 0.0130, Accuracy: 9958/10000 (99.58%)\n",
      "\n",
      " Train Epoch: 51 [59600/60000 (99.33%)]\tLoss: 0.027405\n",
      "Test set: Avg. loss: 0.0125, Accuracy: 9960/10000 (99.60%)\n",
      "\n",
      " Train Epoch: 52 [59600/60000 (99.33%)]\tLoss: 0.011487\n",
      "Test set: Avg. loss: 0.0132, Accuracy: 9961/10000 (99.61%)\n",
      "\n",
      " Train Epoch: 53 [59600/60000 (99.33%)]\tLoss: 0.037939\n",
      "Test set: Avg. loss: 0.0119, Accuracy: 9963/10000 (99.63%)\n",
      "\n",
      " Train Epoch: 54 [59600/60000 (99.33%)]\tLoss: 0.033088\n",
      "Test set: Avg. loss: 0.0134, Accuracy: 9957/10000 (99.57%)\n",
      "\n",
      " Train Epoch: 55 [59600/60000 (99.33%)]\tLoss: 0.019277\n",
      "Test set: Avg. loss: 0.0135, Accuracy: 9959/10000 (99.59%)\n",
      "\n",
      " Train Epoch: 56 [59600/60000 (99.33%)]\tLoss: 0.065451\n",
      "Test set: Avg. loss: 0.0133, Accuracy: 9957/10000 (99.57%)\n",
      "\n",
      " Train Epoch: 57 [59600/60000 (99.33%)]\tLoss: 0.018263\n",
      "Test set: Avg. loss: 0.0126, Accuracy: 9956/10000 (99.56%)\n",
      "\n",
      " Train Epoch: 58 [59600/60000 (99.33%)]\tLoss: 0.023931\n",
      "Test set: Avg. loss: 0.0121, Accuracy: 9957/10000 (99.57%)\n",
      "\n",
      " Train Epoch: 59 [59600/60000 (99.33%)]\tLoss: 0.023753\n",
      "Test set: Avg. loss: 0.0126, Accuracy: 9955/10000 (99.55%)\n",
      "\n",
      " Train Epoch: 60 [59600/60000 (99.33%)]\tLoss: 0.039396\n",
      "Test set: Avg. loss: 0.0117, Accuracy: 9961/10000 (99.61%)\n",
      "\n",
      " Train Epoch: 61 [59600/60000 (99.33%)]\tLoss: 0.034665\n",
      "Test set: Avg. loss: 0.0115, Accuracy: 9963/10000 (99.63%)\n",
      "\n",
      " Train Epoch: 62 [59600/60000 (99.33%)]\tLoss: 0.016055\n",
      "Test set: Avg. loss: 0.0119, Accuracy: 9957/10000 (99.57%)\n",
      "\n",
      " Train Epoch: 63 [59600/60000 (99.33%)]\tLoss: 0.037487\n",
      "Test set: Avg. loss: 0.0121, Accuracy: 9962/10000 (99.62%)\n",
      "\n",
      " Train Epoch: 64 [59600/60000 (99.33%)]\tLoss: 0.010978\n",
      "Test set: Avg. loss: 0.0117, Accuracy: 9962/10000 (99.62%)\n",
      "\n",
      " Train Epoch: 65 [59600/60000 (99.33%)]\tLoss: 0.025268\n",
      "Test set: Avg. loss: 0.0117, Accuracy: 9959/10000 (99.59%)\n",
      "\n",
      " Train Epoch: 66 [59600/60000 (99.33%)]\tLoss: 0.064480\n",
      "Test set: Avg. loss: 0.0109, Accuracy: 9962/10000 (99.62%)\n",
      "\n",
      " Train Epoch: 67 [59600/60000 (99.33%)]\tLoss: 0.028251\n",
      "Test set: Avg. loss: 0.0116, Accuracy: 9960/10000 (99.60%)\n",
      "\n",
      " Train Epoch: 68 [59600/60000 (99.33%)]\tLoss: 0.059267\n",
      "Test set: Avg. loss: 0.0119, Accuracy: 9961/10000 (99.61%)\n",
      "\n",
      " Train Epoch: 69 [59600/60000 (99.33%)]\tLoss: 0.075599\n",
      "Test set: Avg. loss: 0.0114, Accuracy: 9961/10000 (99.61%)\n",
      "\n",
      " Train Epoch: 70 [59600/60000 (99.33%)]\tLoss: 0.025803\n",
      "Test set: Avg. loss: 0.0112, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 71 [59600/60000 (99.33%)]\tLoss: 0.018711\n",
      "Test set: Avg. loss: 0.0111, Accuracy: 9965/10000 (99.65%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 72 [59600/60000 (99.33%)]\tLoss: 0.044482\n",
      "Test set: Avg. loss: 0.0115, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 73 [59600/60000 (99.33%)]\tLoss: 0.031560\n",
      "Test set: Avg. loss: 0.0118, Accuracy: 9962/10000 (99.62%)\n",
      "\n",
      " Train Epoch: 74 [59600/60000 (99.33%)]\tLoss: 0.038981\n",
      "Test set: Avg. loss: 0.0111, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 75 [59600/60000 (99.33%)]\tLoss: 0.031664\n",
      "Test set: Avg. loss: 0.0116, Accuracy: 9955/10000 (99.55%)\n",
      "\n",
      " Train Epoch: 76 [59600/60000 (99.33%)]\tLoss: 0.028519\n",
      "Test set: Avg. loss: 0.0115, Accuracy: 9962/10000 (99.62%)\n",
      "\n",
      " Train Epoch: 77 [59600/60000 (99.33%)]\tLoss: 0.035424\n",
      "Test set: Avg. loss: 0.0111, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 78 [59600/60000 (99.33%)]\tLoss: 0.023906\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 79 [59600/60000 (99.33%)]\tLoss: 0.028247\n",
      "Test set: Avg. loss: 0.0115, Accuracy: 9963/10000 (99.63%)\n",
      "\n",
      " Train Epoch: 80 [59600/60000 (99.33%)]\tLoss: 0.020557\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 9964/10000 (99.64%)\n",
      "\n",
      " Train Epoch: 81 [59600/60000 (99.33%)]\tLoss: 0.023407\n",
      "Test set: Avg. loss: 0.0109, Accuracy: 9964/10000 (99.64%)\n",
      "\n",
      " Train Epoch: 82 [59600/60000 (99.33%)]\tLoss: 0.017848\n",
      "Test set: Avg. loss: 0.0112, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 83 [59600/60000 (99.33%)]\tLoss: 0.028031\n",
      "Test set: Avg. loss: 0.0110, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 84 [59600/60000 (99.33%)]\tLoss: 0.022665\n",
      "Test set: Avg. loss: 0.0106, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 85 [59600/60000 (99.33%)]\tLoss: 0.022779\n",
      "Test set: Avg. loss: 0.0107, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 86 [59600/60000 (99.33%)]\tLoss: 0.040776\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 9963/10000 (99.63%)\n",
      "\n",
      " Train Epoch: 87 [59600/60000 (99.33%)]\tLoss: 0.029982\n",
      "Test set: Avg. loss: 0.0107, Accuracy: 9964/10000 (99.64%)\n",
      "\n",
      " Train Epoch: 88 [59600/60000 (99.33%)]\tLoss: 0.022647\n",
      "Test set: Avg. loss: 0.0113, Accuracy: 9963/10000 (99.63%)\n",
      "\n",
      " Train Epoch: 89 [59600/60000 (99.33%)]\tLoss: 0.012914\n",
      "Test set: Avg. loss: 0.0113, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 90 [59600/60000 (99.33%)]\tLoss: 0.018599\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 9962/10000 (99.62%)\n",
      "\n",
      " Train Epoch: 91 [59600/60000 (99.33%)]\tLoss: 0.038744\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 92 [59600/60000 (99.33%)]\tLoss: 0.031397\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 9968/10000 (99.68%)\n",
      "\n",
      " Train Epoch: 93 [59600/60000 (99.33%)]\tLoss: 0.015229\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 94 [59600/60000 (99.33%)]\tLoss: 0.010111\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 9967/10000 (99.67%)\n",
      "\n",
      " Train Epoch: 95 [59600/60000 (99.33%)]\tLoss: 0.043238\n",
      "Test set: Avg. loss: 0.0113, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 96 [59600/60000 (99.33%)]\tLoss: 0.019168\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 97 [59600/60000 (99.33%)]\tLoss: 0.006533\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 9967/10000 (99.67%)\n",
      "\n",
      " Train Epoch: 98 [59600/60000 (99.33%)]\tLoss: 0.005398\n",
      "Test set: Avg. loss: 0.0106, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 99 [59600/60000 (99.33%)]\tLoss: 0.024512\n",
      "Test set: Avg. loss: 0.0113, Accuracy: 9966/10000 (99.66%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#network_state=torch.load(\"./model.pth\")\n",
    "#network.load_state_dict(network_state)\n",
    "#optimizer_state_dict = torch.load('./optimizer.pth')\n",
    "#optimizer.load_state_dict(optimizer_state_dict)\n",
    "for i in range(0,n_epochs):      \n",
    "      test_counter.append(i*len(train_loader.dataset))\n",
    "      train(i)\n",
    "      test()\n",
    "      torch.save(optimizer.state_dict(), './optimizer.pth')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e820062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 100 [59600/60000 (99.33%)]\tLoss: 0.015309\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 9967/10000 (99.67%)\n",
      "\n",
      " Train Epoch: 101 [59600/60000 (99.33%)]\tLoss: 0.017536\n",
      "Test set: Avg. loss: 0.0110, Accuracy: 9967/10000 (99.67%)\n",
      "\n",
      " Train Epoch: 102 [59600/60000 (99.33%)]\tLoss: 0.019220\n",
      "Test set: Avg. loss: 0.0107, Accuracy: 9968/10000 (99.68%)\n",
      "\n",
      " Train Epoch: 103 [59600/60000 (99.33%)]\tLoss: 0.035966\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 104 [59600/60000 (99.33%)]\tLoss: 0.016364\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 105 [59600/60000 (99.33%)]\tLoss: 0.050716\n",
      "Test set: Avg. loss: 0.0116, Accuracy: 9964/10000 (99.64%)\n",
      "\n",
      " Train Epoch: 106 [59600/60000 (99.33%)]\tLoss: 0.007303\n",
      "Test set: Avg. loss: 0.0107, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 107 [59600/60000 (99.33%)]\tLoss: 0.020629\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 108 [59600/60000 (99.33%)]\tLoss: 0.010061\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 109 [59600/60000 (99.33%)]\tLoss: 0.008621\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 9968/10000 (99.68%)\n",
      "\n",
      " Train Epoch: 110 [59600/60000 (99.33%)]\tLoss: 0.027060\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 9968/10000 (99.68%)\n",
      "\n",
      " Train Epoch: 111 [59600/60000 (99.33%)]\tLoss: 0.010897\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 112 [59600/60000 (99.33%)]\tLoss: 0.027595\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 9968/10000 (99.68%)\n",
      "\n",
      " Train Epoch: 113 [59600/60000 (99.33%)]\tLoss: 0.018877\n",
      "Test set: Avg. loss: 0.0097, Accuracy: 9967/10000 (99.67%)\n",
      "\n",
      " Train Epoch: 114 [59600/60000 (99.33%)]\tLoss: 0.005611\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 9964/10000 (99.64%)\n",
      "\n",
      " Train Epoch: 115 [59600/60000 (99.33%)]\tLoss: 0.011838\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 116 [59600/60000 (99.33%)]\tLoss: 0.012577\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 117 [59600/60000 (99.33%)]\tLoss: 0.017690\n",
      "Test set: Avg. loss: 0.0110, Accuracy: 9964/10000 (99.64%)\n",
      "\n",
      " Train Epoch: 118 [59600/60000 (99.33%)]\tLoss: 0.009594\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 119 [59600/60000 (99.33%)]\tLoss: 0.008807\n",
      "Test set: Avg. loss: 0.0097, Accuracy: 9970/10000 (99.70%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,120):      \n",
    "      test_counter.append(i*len(train_loader.dataset))\n",
    "      train(i)\n",
    "      test()\n",
    "      torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89bac895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 120 [59600/60000 (99.33%)]\tLoss: 0.031876\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 121 [59600/60000 (99.33%)]\tLoss: 0.023167\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 9967/10000 (99.67%)\n",
      "\n",
      " Train Epoch: 122 [59600/60000 (99.33%)]\tLoss: 0.005925\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 9964/10000 (99.64%)\n",
      "\n",
      " Train Epoch: 123 [59600/60000 (99.33%)]\tLoss: 0.008222\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 9968/10000 (99.68%)\n",
      "\n",
      " Train Epoch: 124 [59600/60000 (99.33%)]\tLoss: 0.005937\n",
      "Test set: Avg. loss: 0.0097, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 125 [59600/60000 (99.33%)]\tLoss: 0.019698\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 126 [59600/60000 (99.33%)]\tLoss: 0.014289\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 9972/10000 (99.72%)\n",
      "\n",
      " Train Epoch: 127 [59600/60000 (99.33%)]\tLoss: 0.012819\n",
      "Test set: Avg. loss: 0.0095, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 128 [59600/60000 (99.33%)]\tLoss: 0.018236\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 129 [59600/60000 (99.33%)]\tLoss: 0.014947\n",
      "Test set: Avg. loss: 0.0111, Accuracy: 9966/10000 (99.66%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(120,130):      \n",
    "      test_counter.append(i*len(train_loader.dataset))\n",
    "      train(i)\n",
    "      test()\n",
    "      torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a4f7437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 130 [59600/60000 (99.33%)]\tLoss: 0.016577\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 131 [59600/60000 (99.33%)]\tLoss: 0.020877\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 132 [59600/60000 (99.33%)]\tLoss: 0.009208\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 133 [59600/60000 (99.33%)]\tLoss: 0.010583\n",
      "Test set: Avg. loss: 0.0106, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 134 [59600/60000 (99.33%)]\tLoss: 0.015352\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 135 [59600/60000 (99.33%)]\tLoss: 0.006803\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 136 [59600/60000 (99.33%)]\tLoss: 0.012507\n",
      "Test set: Avg. loss: 0.0092, Accuracy: 9972/10000 (99.72%)\n",
      "\n",
      " Train Epoch: 137 [59600/60000 (99.33%)]\tLoss: 0.016771\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 138 [59600/60000 (99.33%)]\tLoss: 0.019832\n",
      "Test set: Avg. loss: 0.0091, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 139 [59600/60000 (99.33%)]\tLoss: 0.022129\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 140 [59600/60000 (99.33%)]\tLoss: 0.021171\n",
      "Test set: Avg. loss: 0.0095, Accuracy: 9967/10000 (99.67%)\n",
      "\n",
      " Train Epoch: 141 [59600/60000 (99.33%)]\tLoss: 0.017865\n",
      "Test set: Avg. loss: 0.0097, Accuracy: 9972/10000 (99.72%)\n",
      "\n",
      " Train Epoch: 142 [59600/60000 (99.33%)]\tLoss: 0.044291\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 143 [59600/60000 (99.33%)]\tLoss: 0.003358\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 144 [59600/60000 (99.33%)]\tLoss: 0.015777\n",
      "Test set: Avg. loss: 0.0112, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 145 [59600/60000 (99.33%)]\tLoss: 0.020150\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 146 [59600/60000 (99.33%)]\tLoss: 0.021342\n",
      "Test set: Avg. loss: 0.0094, Accuracy: 9967/10000 (99.67%)\n",
      "\n",
      " Train Epoch: 147 [59600/60000 (99.33%)]\tLoss: 0.024418\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 148 [59600/60000 (99.33%)]\tLoss: 0.016801\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 149 [59600/60000 (99.33%)]\tLoss: 0.005122\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 9969/10000 (99.69%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(130,150):      \n",
    "      test_counter.append(i*len(train_loader.dataset))\n",
    "      train(i)\n",
    "      test()\n",
    "      torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95090e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 150 [59600/60000 (99.33%)]\tLoss: 0.029319\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 151 [59600/60000 (99.33%)]\tLoss: 0.010298\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 9964/10000 (99.64%)\n",
      "\n",
      " Train Epoch: 152 [59600/60000 (99.33%)]\tLoss: 0.013698\n",
      "Test set: Avg. loss: 0.0096, Accuracy: 9972/10000 (99.72%)\n",
      "\n",
      " Train Epoch: 153 [59600/60000 (99.33%)]\tLoss: 0.012595\n",
      "Test set: Avg. loss: 0.0097, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 154 [59600/60000 (99.33%)]\tLoss: 0.018754\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 155 [59600/60000 (99.33%)]\tLoss: 0.021121\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 9968/10000 (99.68%)\n",
      "\n",
      " Train Epoch: 156 [59600/60000 (99.33%)]\tLoss: 0.010302\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 9972/10000 (99.72%)\n",
      "\n",
      " Train Epoch: 157 [59600/60000 (99.33%)]\tLoss: 0.004508\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 158 [59600/60000 (99.33%)]\tLoss: 0.042210\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 159 [59600/60000 (99.33%)]\tLoss: 0.007687\n",
      "Test set: Avg. loss: 0.0096, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 160 [59600/60000 (99.33%)]\tLoss: 0.012854\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 9968/10000 (99.68%)\n",
      "\n",
      " Train Epoch: 161 [59600/60000 (99.33%)]\tLoss: 0.045184\n",
      "Test set: Avg. loss: 0.0107, Accuracy: 9963/10000 (99.63%)\n",
      "\n",
      " Train Epoch: 162 [59600/60000 (99.33%)]\tLoss: 0.020546\n",
      "Test set: Avg. loss: 0.0097, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 163 [59600/60000 (99.33%)]\tLoss: 0.027962\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 164 [59600/60000 (99.33%)]\tLoss: 0.008900\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 9968/10000 (99.68%)\n",
      "\n",
      " Train Epoch: 165 [59600/60000 (99.33%)]\tLoss: 0.038754\n",
      "Test set: Avg. loss: 0.0097, Accuracy: 9972/10000 (99.72%)\n",
      "\n",
      " Train Epoch: 166 [59600/60000 (99.33%)]\tLoss: 0.010272\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 9968/10000 (99.68%)\n",
      "\n",
      " Train Epoch: 167 [59600/60000 (99.33%)]\tLoss: 0.007541\n",
      "Test set: Avg. loss: 0.0109, Accuracy: 9967/10000 (99.67%)\n",
      "\n",
      " Train Epoch: 168 [59600/60000 (99.33%)]\tLoss: 0.011686\n",
      "Test set: Avg. loss: 0.0107, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 169 [59600/60000 (99.33%)]\tLoss: 0.010862\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 9970/10000 (99.70%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(150,170):      \n",
    "      test_counter.append(i*len(train_loader.dataset))\n",
    "      train(i)\n",
    "      test()\n",
    "      torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1662965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train Epoch: 170 [59600/60000 (99.33%)]\tLoss: 0.018366\n",
      "Test set: Avg. loss: 0.0093, Accuracy: 9974/10000 (99.74%)\n",
      "\n",
      " Train Epoch: 171 [59600/60000 (99.33%)]\tLoss: 0.011411\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 172 [59600/60000 (99.33%)]\tLoss: 0.017258\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 9973/10000 (99.73%)\n",
      "\n",
      " Train Epoch: 173 [59600/60000 (99.33%)]\tLoss: 0.026713\n",
      "Test set: Avg. loss: 0.0096, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 174 [59600/60000 (99.33%)]\tLoss: 0.011810\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 175 [59600/60000 (99.33%)]\tLoss: 0.019943\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 176 [59600/60000 (99.33%)]\tLoss: 0.039365\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 177 [59600/60000 (99.33%)]\tLoss: 0.012365\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 9966/10000 (99.66%)\n",
      "\n",
      " Train Epoch: 178 [59600/60000 (99.33%)]\tLoss: 0.034894\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 179 [59600/60000 (99.33%)]\tLoss: 0.035404\n",
      "Test set: Avg. loss: 0.0102, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 180 [59600/60000 (99.33%)]\tLoss: 0.020276\n",
      "Test set: Avg. loss: 0.0103, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 181 [59600/60000 (99.33%)]\tLoss: 0.016941\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 182 [59600/60000 (99.33%)]\tLoss: 0.014231\n",
      "Test set: Avg. loss: 0.0108, Accuracy: 9965/10000 (99.65%)\n",
      "\n",
      " Train Epoch: 183 [59600/60000 (99.33%)]\tLoss: 0.032732\n",
      "Test set: Avg. loss: 0.0107, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 184 [59600/60000 (99.33%)]\tLoss: 0.005316\n",
      "Test set: Avg. loss: 0.0101, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 185 [59600/60000 (99.33%)]\tLoss: 0.021518\n",
      "Test set: Avg. loss: 0.0110, Accuracy: 9969/10000 (99.69%)\n",
      "\n",
      " Train Epoch: 186 [59600/60000 (99.33%)]\tLoss: 0.045795\n",
      "Test set: Avg. loss: 0.0105, Accuracy: 9967/10000 (99.67%)\n",
      "\n",
      " Train Epoch: 187 [59600/60000 (99.33%)]\tLoss: 0.008295\n",
      "Test set: Avg. loss: 0.0096, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 188 [59600/60000 (99.33%)]\tLoss: 0.010714\n",
      "Test set: Avg. loss: 0.0099, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 189 [59600/60000 (99.33%)]\tLoss: 0.007023\n",
      "Test set: Avg. loss: 0.0095, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 190 [59600/60000 (99.33%)]\tLoss: 0.013386\n",
      "Test set: Avg. loss: 0.0104, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 191 [59600/60000 (99.33%)]\tLoss: 0.013733\n",
      "Test set: Avg. loss: 0.0093, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 192 [59600/60000 (99.33%)]\tLoss: 0.031469\n",
      "Test set: Avg. loss: 0.0093, Accuracy: 9971/10000 (99.71%)\n",
      "\n",
      " Train Epoch: 193 [59600/60000 (99.33%)]\tLoss: 0.027766\n",
      "Test set: Avg. loss: 0.0089, Accuracy: 9975/10000 (99.75%)\n",
      "\n",
      " Train Epoch: 194 [59600/60000 (99.33%)]\tLoss: 0.005077\n",
      "Test set: Avg. loss: 0.0091, Accuracy: 9975/10000 (99.75%)\n",
      "\n",
      " Train Epoch: 195 [59600/60000 (99.33%)]\tLoss: 0.019680\n",
      "Test set: Avg. loss: 0.0086, Accuracy: 9976/10000 (99.76%)\n",
      "\n",
      " Train Epoch: 196 [59600/60000 (99.33%)]\tLoss: 0.002771\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 197 [59600/60000 (99.33%)]\tLoss: 0.007031\n",
      "Test set: Avg. loss: 0.0098, Accuracy: 9970/10000 (99.70%)\n",
      "\n",
      " Train Epoch: 198 [59600/60000 (99.33%)]\tLoss: 0.005099\n",
      "Test set: Avg. loss: 0.0095, Accuracy: 9973/10000 (99.73%)\n",
      "\n",
      " Train Epoch: 199 [59600/60000 (99.33%)]\tLoss: 0.028557\n",
      "Test set: Avg. loss: 0.0100, Accuracy: 9970/10000 (99.70%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(170,200):      \n",
    "      test_counter.append(i*len(train_loader.dataset))\n",
    "      train(i)\n",
    "      test()\n",
    "      torch.save(optimizer.state_dict(), './optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf5ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
